# -*- coding: utf-8 -*-
"""Gradient Boosting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fqsLDH-GkQVy0kv6aEgOyOeFh2TByycd
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score

import lightgbm as lgb
import xgboost as xgb
import catboost as cb
from catboost import CatBoostClassifier, Pool

import sklearn.datasets
import gc

"""### Data Prep."""

# train_X = pd.read_csv('music_data/train_X.csv')
train_X = pd.read_csv('music_data/train_X_date_converted.csv')
train_y = pd.read_csv('music_data/train_Y.csv')

# val_X = pd.read_csv('music_data/valid_X.csv')
val_X = pd.read_csv('music_data/valid_X_date_converted.csv')
val_y = pd.read_csv('music_data/valid_Y.csv')

# test_X = pd.read_csv('music_data/test_X.csv')
test_X = pd.read_csv('music_data/test_X_date_converted.csv')
test_y = pd.read_csv('music_data/test_Y.csv')

# train_tiny_X = pd.read_csv('music_data/train_tiny_X.csv')
train_tiny_X = train_X[:10000].copy()
train_tiny_y = train_y[:10000].copy()

val_tiny_X = val_X[:1000].copy()
#val_tiny_X = pd.read_csv('music_data/val_tiny_X_date_converted.csv')
val_tiny_y = val_y[:1000].copy()

# Observing reasonable date for date time conversion
# 2004 seems to be the earliest date. '1970-01-01' is essentially null value (1 in train).
print('train x', train_X['registration_init_time'].min(), train_X['expiration_date'].min())
print('val x', val_X['registration_init_time'].min(), val_X['expiration_date'].min())
print('test x', test_X['registration_init_time'].min(), test_X['expiration_date'].min())


# Not many records smaller than '2000-01-01'. Reasonable to not treat them specially
print(train_X['expiration_date'].apply(lambda date: date == '1970-01-01').sum(), '1970-01-01 in train set')
print(val_X['expiration_date'].apply(lambda date: date == '1970-01-01').sum(), '1970-01-01 in val set')

print(train_X['expiration_date'].apply(lambda date: date < '2000-01-01').sum(), 'smaller than 2000-01-01 in train set')
print(val_X['expiration_date'].apply(lambda date: date < '2000-01-01').sum(), 'smaller than 2000-01-01 in val set')

def date_to_int(column, base_date=datetime.strptime('2000-01-01', "%Y-%m-%d")):
    """
    Convert date to day counts since base_date for given columns.
    
    :param column: pandas column containing date representations as str value
    :param base_date: base date from which date is counted. i.e. 2000-01-02 will be day '1' comparing to '2000-01-01'
    """
    
    def date_diff(date):
        date = datetime.strptime(date, "%Y-%m-%d")
        return (date - base_date).days
    
    return column.apply(date_diff)

def convert_date_columns_to_int(dataframes, cols=['registration_init_time', 'expiration_date'], saving=True):
    count = 0
    total = len(dataframes)
    for df_name, df in dataframes.items():
        count += 1
        print("Starting {} ...".format(df_name))
        for col in cols:
            df[col+'_int'] = date_to_int(df[col])
        df = df.drop(columns=cols)
        dataframes[df_name] = df
        
        if saving:
            print("Saving {} ...".format(df_name))
            df.to_csv('music_data/'+ df_name + '_date_converted.csv')
        
        print("====== Done {} / {} ======".format(count, total))
    return dataframes

# Converting all data
converted_dfs = convert_date_columns_to_int({
    'train_X': train_X,
    'valid_X': val_X,
    'test_X': test_X,
    'train_tiny_X': train_tiny_X,
    'val_tiny_X': val_tiny_X,
})
train_X = converted_dfs['train_X']
val_X = converted_dfs['valid_X']
test_X = converted_dfs['test_X']
train_tiny_X = converted_dfs['train_tiny_X']
val_tiny_X = converted_dfs['val_tiny_X']

"""## Gradient Boosting

### LightGBM
"""

def run_lgbc(train_X, train_y, val_X, val_y):
    params = {
        "objective" : "binary",
        "metric" : "binary_logloss", 
        "num_leaves" : 30,
        "min_child_samples" : 100,
        "learning_rate" : 0.1,
        "bagging_fraction" : 0.7,
        "feature_fraction" : 0.5,
        "bagging_frequency" : 5,
        "bagging_seed" : 2018,
    }
    
    lgtrain = lgb.Dataset(train_X, label=train_y)
    lgval = lgb.Dataset(val_X, label=val_y)
    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)

    pred_val_y = model.predict(val_X, num_iteration=model.best_iteration)
    return model, pred_val_y

"""#### Testing on tiny dataset"""

modelC, pred_val_y = run_lgbc(train_tiny_X, train_tiny_y['target'], val_tiny_X, val_tiny_y['target'])
print(classification_report(val_tiny_y['target'], modelC.predict(val_tiny_X)>0.5))
print(roc_auc_score(val_tiny_y['target'], modelC.predict(val_tiny_X)))

"""#### Running large data"""

modelC, pred_val_y = run_lgbc(train_X, train_y['target'], val_X, val_y['target'])
print(classification_report(val_y['target'], modelC.predict(val_X)>0.5))
print(roc_auc_score(val_y['target'], modelC.predict(val_X)))

"""### CatBoosting"""

train_X.head()

train_X.info()
val_X.info()

val_X.head()

train_X.shape

cat_features = [2,3,4,5,6,8,9,10,11,12,13,14,15,16]

def run_cb(train_X, train_y, val_X, val_y, cat_features,iterations=300):
    model_cb = cb.CatBoostClassifier(
        iterations=iterations, 
        learning_rate=0.1, 
        depth=6, 
        loss_function='Logloss',
        thread_count=30,
        random_seed=229,
        use_best_model = True,
        l2_leaf_reg = 2
    )
    eval_dataset = Pool(val_X,val_y,cat_features=cat_features)
    
    model = model_cb.fit(train_X, train_y,cat_features,eval_set=eval_dataset,verbose_eval=25,early_stopping_rounds = 100)

    pred_val_y = model.predict(val_X)
    return model, pred_val_y

# Tiny dataset
model_cb, pred_val_y = run_cb(train_tiny_X, train_tiny_y['target'], val_tiny_X, val_tiny_y['target'],cat_features)

#Analysis
print(classification_report(val_tiny_y['target'], pred_val_y>0.5))
print(roc_auc_score(val_tiny_y['target'],pred_val_y))

model_cb.get_feature_importance()

#save score
np.savez('output/catboost_small.npz', val_target=val_tiny_y['target'], val_preds= pred_val_y)

#load score
val_scores = np.load('output/catboost_small.npz')
val_scores.files

val_scores['val_preds'][:10]

# Full dataset
model_cb, pred_val_y = run_cb(train_X, train_y['target'], val_X, val_y['target'], 200)
print(classification_report(val_y['target'], model_cb.predict(val_X)>0.5))
print(roc_auc_score(val_y['target'], model_cb.predict(val_X)))

model_cb, pred_val_y = run_cb(train_X, train_y['target'], val_X, val_y['target'], 20)
print(classification_report(val_y['target'], model_cb.predict(val_X)>0.5))
print(roc_auc_score(val_y['target'], model_cb.predict(val_X)))

